{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880c320a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time w/o python interpreter load/terminate:  3.134254217147827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sparse_activations.py:46: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "C:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sparse_activations.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "C:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sru.py:395: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "C:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sru.py:444: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "[2025-07-16 15:37:13,856 INFO] Loading checkpoint from models/model_step_10000.pt\n",
      "[2025-07-16 15:37:16,531 INFO] Loading data into the model\n",
      "[2025-07-16 15:37:16,987 INFO] PRED SCORE: -0.0178, PRED PPL: 1.02 NB SENTENCES: 1\n"
     ]
    }
   ],
   "source": [
    "!onmt_translate \\\n",
    "  -model models/model_step_10000.pt \\\n",
    "  -src input.txt \\\n",
    "  -output output.txt \\\n",
    "  -beam_size 5 \\\n",
    "  -batch_size 32 \\\n",
    "  --src_subword_model sentencepiece.model \\\n",
    "  --tgt_subword_model sentencepiece.model \\\n",
    "  --gpu 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0aa815",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, predictions = global_translator.translate_batch(batch)\n",
    "\n",
    "print(\"Raw predictions:\", predictions)\n",
    "\n",
    "if predictions and len(predictions[0]) > 0:\n",
    "    pred_ids = predictions[0][0]\n",
    "    print(\"Predicted token IDs:\", pred_ids)\n",
    "\n",
    "    if isinstance(pred_ids, torch.Tensor):\n",
    "        pred_ids = pred_ids.cpu().tolist()\n",
    "\n",
    "    # í† í°ì„ ìŠ¤í˜ì…œ í† í° ì œì™¸í•˜ê³  ì¶œë ¥í•´ë³´ê¸°\n",
    "    special_ids = {translator._tgt_pad_idx, global_translator._tgt_bos_idx,\n",
    "                   translator._tgt_eos_idx, global_translator._tgt_unk_idx}\n",
    "    filtered_ids = [tid for tid in pred_ids if tid not in special_ids]\n",
    "    print(\"Filtered token IDs:\", filtered_ids)\n",
    "\n",
    "    # ë””ì½”ë”© ì‹œë„\n",
    "    decoded_text = sp.decode_ids(filtered_ids)\n",
    "    print(\"Decoded text:\", decoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242a9804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [23303, 19608]\n",
      "Tokens as pieces: ['â–ì•ˆë…•', 'í•˜ì„¸ìš”']\n",
      "Vocab size: 30000\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"sentencepiece.model\")\n",
    "\n",
    "text = \"ì•ˆë…•í•˜ì„¸ìš”\"\n",
    "tokens = sp.encode(text, out_type=int)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Tokens as pieces:\", sp.encode(text, out_type=str))\n",
    "print(\"Vocab size:\", sp.get_piece_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5b4d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sparse_activations.py:46: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sparse_activations.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sru.py:395: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sru.py:444: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n"
     ]
    }
   ],
   "source": [
    "from model_class import KoreanEnglishTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5ae4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_translator = KoreanEnglishTranslator(\n",
    "    model_path='models/model_step_10000.pt',\n",
    "    tokenizer_path='sentencepiece.model',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b879309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: [610, 28911, 29297, 29060, 6934, 28978]\n",
      "src_tensor.shape: torch.Size([1, 6, 1])\n",
      "src_len.shape: torch.Size([1]), src_len: tensor([6])\n",
      "âœ… [í…ŒìŠ¤íŠ¸] embedding output shape: torch.Size([1, 6, 500])\n",
      "ğŸ” [run_encoder] src.shape: torch.Size([1, 6, 1])\n",
      "ğŸ” [run_encoder] src_len: tensor([6], device='cuda:0')\n",
      "[RNNEncoder.forward] input src shape: torch.Size([1, 6, 1])\n",
      "[RNNEncoder.forward] after embeddings shape: torch.Size([1, 6, 500])\n",
      "[RNNEncoder.forward] packed_emb shape: PackedSequence\n",
      "[RNNEncoder.forward] enc_out shape: PackedSequence\n",
      "[RNNEncoder.forward] unpacked enc_out shape: torch.Size([1, 6, 500])\n",
      "âœ… [run_encoder] Encoder ran successfully.\n",
      "ğŸ” [init_state] src.shape: torch.Size([1, 6, 1])\n",
      "ğŸ” [init_state] type(enc_final_hs): <class 'tuple'>\n",
      "  ğŸ”¸ h_n shape: torch.Size([2, 1, 500])\n",
      "  ğŸ”¸ c_n shape: torch.Size([2, 1, 500])\n",
      "âœ… [init_state] hidden state initialized with batch size: 1\n",
      "Translation error: 'coverage'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_english = global_translator.translate(\"ë°˜ê°€ì›Œìš” ì¹œêµ¬ë“¤\")\n",
    "print(predicted_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "281f9a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder: <class 'onmt.encoders.rnn_encoder.RNNEncoder'>\n",
      "encoder.rnn: LSTM(500, 500, num_layers=2, batch_first=True, dropout=0.3)\n",
      "batch_first: True\n"
     ]
    }
   ],
   "source": [
    "print(\"encoder:\", type(global_translator.translator.model.encoder))\n",
    "print(\"encoder.rnn:\", global_translator.translator.model.encoder.rnn)\n",
    "\n",
    "# batch_first ê°’ í™•ì¸\n",
    "print(\"batch_first:\", global_translator.translator.model.encoder.rnn.batch_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3340b059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder: <class 'onmt.decoders.decoder.InputFeedRNNDecoder'>\n",
      "encoder.rnn: StackedLSTM(\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): LSTMCell(1000, 500)\n",
      "    (1): LSTMCell(500, 500)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"encoder:\", type(global_translator.translator.model.decoder))\n",
    "print(\"encoder.rnn:\", global_translator.translator.model.decoder.rnn)\n",
    "\n",
    "# batch_first ê°’ í™•ì¸\n",
    "# print(\"batch_first:\", global_translator.translator.model.decoder.rnn.batch_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = global_translator.embeddings(src)\n",
    "print(\"[RNNEncoder.forward] embedding output shape:\", emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946e77b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daycon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
