{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6975264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m onmt.bin.translate \\\n",
    "    -model models/model_step_5000.pt \\\n",
    "    -src test.tok.ko \\\n",
    "    -output output.tok.en \\\n",
    "    -beam_size 5 \\\n",
    "    -gpu 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b9f072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['‚ñÅÏïàÎÖï', 'ÌïòÏÑ∏Ïöî']\n",
      "['‚ñÅÌïúÍµ≠Ïñ¥', '‚ñÅÎ¨∏', 'Ïû•', '‚ñÅÌÖåÏä§Ìä∏', 'ÏûÖÎãàÎã§', '.']\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('sentencepiece.model')\n",
    "\n",
    "print(sp.encode_as_pieces(\"ÏïàÎÖïÌïòÏÑ∏Ïöî\"))\n",
    "print(sp.encode_as_pieces(\"ÌïúÍµ≠Ïñ¥ Î¨∏Ïû• ÌÖåÏä§Ìä∏ÏûÖÎãàÎã§.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5b4d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sparse_activations.py:46: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sparse_activations.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sru.py:395: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "c:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\onmt\\modules\\sru.py:444: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n"
     ]
    }
   ],
   "source": [
    "from model_class import KoreanEnglishTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ae4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_translator = KoreanEnglishTranslator(\n",
    "    tokenizer_path='sentencepiece.model',\n",
    "    model_path='models/model_step_3000.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d592e89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâ token_ids: [55, 13526, 28926, 28041, 3335, 18758, 12125, 8144, 227, 29253, 13663, 4178, 9829, 2075, 2662, 1037, 615, 1844, 5436, 28906, 653, 29243, 17580, 2015, 9984, 1219, 28876, 28907, 28962, 28890, 28961, 28928, 5864, 8377, 729, 28895]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NMTModel' object has no attribute 'src_emb'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bleu_score\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# ÌèâÍ∞Ä Ïã§Ìñâ\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m bleu = \u001b[43mevaluate_translation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_translator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest.ko\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest.en\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(bleu)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mevaluate_translation\u001b[39m\u001b[34m(translator, test_file_ko, test_file_en)\u001b[39m\n\u001b[32m     13\u001b[39m reference_english = en_line.strip()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Î≤àÏó≠ Ïã§Ìñâ\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m predicted_english = \u001b[43mtranslator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkorean_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# BLEU Í≥ÑÏÇ∞Ïö© Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\u001b[39;00m\n\u001b[32m     19\u001b[39m references.append([reference_english.split()])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ï†ïÏ£ºÌôò\\Desktop\\Opennmt-translate-ko-en-\\model_result\\model_class.py:55\u001b[39m, in \u001b[36mKoreanEnglishTranslator.translate\u001b[39m\u001b[34m(self, korean_text)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müëâ token_ids:\u001b[39m\u001b[33m\"\u001b[39m, token_ids)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# vocab size ÌôïÏù∏\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m vocab_size = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtranslator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msrc_emb\u001b[49m.weight.size(\u001b[32m0\u001b[39m)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m token_ids:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m idx >= vocab_size:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Anaconda3\\envs\\daycon\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'NMTModel' object has no attribute 'src_emb'"
     ]
    }
   ],
   "source": [
    "def evaluate_translation(translator, test_file_ko, test_file_en):\n",
    "    \"\"\"Î≤àÏó≠ ÏÑ±Îä• ÌèâÍ∞Ä (BLEU Ïä§ÏΩîÏñ¥)\"\"\"\n",
    "    from nltk.translate.bleu_score import corpus_bleu\n",
    "    \n",
    "    references = []\n",
    "    predictions = []\n",
    "    \n",
    "    with open(test_file_ko, 'r', encoding='utf-8') as f_ko, \\\n",
    "         open(test_file_en, 'r', encoding='utf-8') as f_en:\n",
    "        \n",
    "        for ko_line, en_line in zip(f_ko, f_en):\n",
    "            korean_text = ko_line.strip()\n",
    "            reference_english = en_line.strip()\n",
    "            \n",
    "            # Î≤àÏó≠ Ïã§Ìñâ\n",
    "            predicted_english = translator.translate(korean_text)\n",
    "            \n",
    "            # BLEU Í≥ÑÏÇ∞Ïö© Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\n",
    "            references.append([reference_english.split()])\n",
    "            predictions.append(predicted_english.split())\n",
    "    \n",
    "    # BLEU Ïä§ÏΩîÏñ¥ Í≥ÑÏÇ∞\n",
    "    bleu_score = corpus_bleu(references, predictions)\n",
    "    print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "    \n",
    "    return bleu_score\n",
    "\n",
    "# ÌèâÍ∞Ä Ïã§Ìñâ\n",
    "bleu = evaluate_translation(global_translator, 'test.ko', 'test.en')\n",
    "print(bleu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c109dcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_param', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'count_parameters', 'cpu', 'cuda', 'decoder', 'double', 'dump_patches', 'encoder', 'eval', 'extra_repr', 'float', 'forward', 'generator', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'ipu', 'load_safe_state_dict', 'load_state_dict', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'update_dropout', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(global_translator.translator.model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40922607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î™®Îç∏ vocab size: 19688\n"
     ]
    }
   ],
   "source": [
    "vocab_size = None\n",
    "\n",
    "# 1) encoder ÏïàÏóê embeddings ÏÜçÏÑ± ÏûàÎäîÏßÄ ÌôïÏù∏\n",
    "if hasattr(global_translator.translator.model.encoder, 'embeddings'):\n",
    "    emb = global_translator.translator.model.encoder.embeddings\n",
    "    # embeddings ÎÇ¥Î∂Ä Íµ¨Ï°∞Ïóê Îî∞Îùº Îã§Î¶Ñ\n",
    "    if hasattr(emb, 'word_lut'):\n",
    "        vocab_size = emb.word_lut.weight.size(0)\n",
    "    elif hasattr(emb, 'weight'):\n",
    "        vocab_size = emb.weight.size(0)\n",
    "\n",
    "\n",
    "\n",
    "if vocab_size is None:\n",
    "    raise RuntimeError(\"vocab sizeÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\")\n",
    "\n",
    "print(\"Î™®Îç∏ vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c30e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daycon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
